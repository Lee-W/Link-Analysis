{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Algorithm Implementation](#implement)\n",
    "    - [Hits](#hits)\n",
    "    - [PageRank](#pagerank)\n",
    "    - [SimRank](#simrank)\n",
    "- [Discussion](#discussion)\n",
    "    - [Result Analysis](#result)\n",
    "    - [Computation Performance Analysis](#performance)\n",
    "    - [Find a way to increase hub, authority](#increase-hub-authority)\n",
    "    - [Find a way to increase pagerank](#increase-pagerank)\n",
    "    - [Can link analysis algorithms really find the “important” pages from Web?](#important)\n",
    "    - [What is the effect of “C” parameter in SimRank?](#c-in-simrank)  \n",
    "    - [What are practical issues when implement these algorithms in a real Web?](#practical-issue)  \n",
    "- [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <a name='setup'></a> Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "from pprint import PrettyPrinter\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.exception import NetworkXError\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp = PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Edge = namedtuple('Edge', ('source', 'dest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_graph_gen(filename):\n",
    "    with open(filename, 'r') as input_file:\n",
    "        for line in input_file:\n",
    "            source, dest = line.strip().split(',')\n",
    "            yield Edge(source, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FILENAME_TEMPLATE = 'dataset/graph_{num}.txt'\n",
    "NUMBER_OF_GRAPHS = 8\n",
    "\n",
    "graphs = list()\n",
    "for i in range(1, NUMBER_OF_GRAPHS+1):\n",
    "    filename = FILENAME_TEMPLATE.format(num=i)\n",
    "    graph_gen = load_graph_gen(filename)\n",
    "    graphs.append(nx.DiGraph(graph_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_graphs(graphs, method='plt'):\n",
    "    def plt_visulize(index, graph):\n",
    "        plt.figure(index)\n",
    "        plt.title('graph {index}'.format(index=index))\n",
    "        nx.draw(graph, arrows=True, with_labels=True)\n",
    "        \n",
    "    def pvg_visulize(index, graph):\n",
    "        A = to_agraph(graph)\n",
    "        print('graph {index}'.format(index=index))\n",
    "        display(Image(A.draw(format='png', prog='dot')))\n",
    "        \n",
    "    if method == 'plt':\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        visulize_method = plt_visulize\n",
    "    elif method == 'pgv':\n",
    "        from networkx.drawing.nx_agraph import to_agraph\n",
    "        import pygraphviz as pgv\n",
    "        import pydot_ng as pydot\n",
    "        from IPython.display import Image, display\n",
    "        \n",
    "        visulize_method = pvg_visulize\n",
    "        \n",
    "    for index, graph in enumerate(graphs, 1):\n",
    "        visulize_method(index, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_graphs(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Algorithm  Implementation\n",
    "\n",
    "## <a name='hits'></a> Hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Implement of HITS (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initGraph(G):\n",
    "    for node in G:\n",
    "        G.add_node(node, authority=1)\n",
    "        G.add_node(node, hub=1)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalized(G, h, a):\n",
    "    totalH, totalA, t = 0, 0, 0\n",
    "    for node in G:\n",
    "        totalH += h[node]\n",
    "        totalA += a[node]\n",
    "    for node in G:\n",
    "        #t += abs(h[node] / totalH - G.node[node]['hub'])\n",
    "        t += abs(a[node] / totalA - G.node[node]['authority'])\n",
    "        G.node[node]['hub'] = h[node] / totalH\n",
    "        G.node[node]['authority'] = a[node] / totalA\n",
    "    return G,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def authorityHub(G, h, a):\n",
    "    for node in G:\n",
    "        h[node], a[node] = 0,0\n",
    "        for ch in G.successors(node):\n",
    "            h[node] += G.node[ch]['authority']\n",
    "        for pa in G.predecessors(node):\n",
    "            a[node] += G.node[pa]['hub']\n",
    "    G,t = normalized(G,h,a)\n",
    "    return G,h,a,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HITS(G, max_iter=100, tol=1e-08, nstart=None, normalized=True):\n",
    "    h, a = {}, {}\n",
    "    initGraph(G)\n",
    "    it, t = 0, 1\n",
    "    while it < max_iter and t > tol:\n",
    "        G,h,a,t = authorityHub(G,h,a)\n",
    "        print(it,t)\n",
    "        it += 1\n",
    "    for node in G:\n",
    "        h[node] = G.node[node]['hub']\n",
    "        a[node] = G.node[node]['authority']        \n",
    "    return h,a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Implement of HITS (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maximal(m):\n",
    "    #total = np.sqrt(np.sum(np.square(np.abs(m))))\n",
    "    maximum = np.max(np.abs(m))\n",
    "    return m/maximum #total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal(m):\n",
    "    total = np.sum(np.abs(m))\n",
    "    return m/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare(m1, m2):\n",
    "    result = np.sum(np.abs(m1-m2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hits(G, max_iter=100, tol=1e-08, nstart=None, normalized=True):\n",
    "    k = G.number_of_nodes()\n",
    "    nodeDict, Hub, Auth = {}, {}, {}\n",
    "    i, it, t = 0, 0, 1\n",
    "    for node in G:\n",
    "        nodeDict[node] = i\n",
    "        i += 1\n",
    "        \n",
    "    A = np.zeros((k, k))\n",
    "    for node in G:    \n",
    "        for n in G.neighbors(node):\n",
    "            A[nodeDict[node]][nodeDict[n]] = 1\n",
    "    A.shape=(k,k)  \n",
    "    AT = np.transpose(A)\n",
    "    \n",
    "    h = np.ones((k,1))/k\n",
    "    a = np.ones((k,1))/k \n",
    "    \n",
    "    while it <= max_iter and t > tol:\n",
    "        pre_h = h\n",
    "        a = maximal(AT.dot(pre_h))\n",
    "        h = maximal(A.dot(a))\n",
    "    \n",
    "        t = compare(h, pre_h)# + compare(a, pre_a)\n",
    "        it += 1\n",
    "    \n",
    "    h = normal(h)\n",
    "    a = normal(a)\n",
    "    for key in nodeDict.keys():\n",
    "        Hub[key] = h[nodeDict[key]][0]\n",
    "        Auth[key] = a[nodeDict[key]][0]\n",
    "        \n",
    "    return Hub, Auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HITS algorithm is implemented in two way.  \n",
    "The difference between them is the way to store the weight of hub and authority.   \n",
    "The former implementation stores them in graph while the latter one store them in matrixes ,which improving the efficiency of calculating the weights.  \n",
    "The main concept of implementing HITS is the same, so I will focus on the second implentation in the following paragraphs.  \n",
    "* Step 1: create a matrix A to store the connection(links) between nodes.  \n",
    "* Step 2: take two matrices as scores of hub and authority whose dimension are both k x 1 where k represents the number of nodes and initialize all of element with 1.  \n",
    "* Step 3: update the score of authority with the dot product of the transpose of A and the score of hub.  \n",
    "* Step 4: update the score of hub with the dot product of A and the new score of authority.  \n",
    "* Step 5: normalize them and calculate the tolerance. if the tolerance is too high and iteration counter is lower than max_iter, repeat the step2~5.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <a name='pagerank'></a> Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pagerank(graph: nx.classes.digraph.DiGraph,\n",
    "             *, alpha: float = 0.85, epsilon: float = 1e-06) -> Dict[object, float]:\n",
    "    \"\"\"Page Rank\n",
    "    \n",
    "    Args:\n",
    "        graph: Networkx Directed Graph\n",
    "        alpha: 1 - damping factor\n",
    "        epsilon: The threshold to teminate iterations\n",
    "        \n",
    "    Returns:\n",
    "        Pageranks of each nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    node_num = graph.number_of_nodes()\n",
    "    adj_matrix = np.array(nx.to_numpy_matrix(graph))\n",
    "    out_degs = np.sum(adj_matrix, axis=1)\n",
    "    damping_factor = 1 - alpha\n",
    "    \n",
    "    # Nodes with no outgoing edges\n",
    "    dangle_nodes = [\n",
    "        index\n",
    "        for index, o_deg in enumerate(graph.out_degree().values())\n",
    "        if not o_deg\n",
    "    ]\n",
    "    \n",
    "    # Page Ranks\n",
    "    prs = np.array([1/node_num for _ in range(node_num)])\n",
    "    # Page Ranks in previous iteration\n",
    "    pre_prs = np.array([0 for _ in range(node_num)])\n",
    "    \n",
    "    delta = np.sum(np.abs(prs - pre_prs))\n",
    "    while delta > epsilon:\n",
    "        pre_prs = deepcopy(prs)\n",
    "        \n",
    "        # Page Rank values each node can contribute in each edge\n",
    "        pr_quotas = np.array(\n",
    "            [pr/deg if deg else 0 for pr, deg in zip(pre_prs, out_degs)]\n",
    "        )\n",
    "        dangle_sum = np.sum([pre_prs[dangle_node]/node_num\n",
    "                             for dangle_node in dangle_nodes])\n",
    "\n",
    "        prs = (\n",
    "            damping_factor / node_num +\n",
    "            alpha *\n",
    "            (\n",
    "                pr_quotas.dot(adj_matrix) + \n",
    "                dangle_sum\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Normalize\n",
    "        prs /= np.sum(prs)\n",
    "        delta = np.sum(np.abs(prs - pre_prs))\n",
    "        \n",
    "    # Mapping node name to its page rank\n",
    "    prs_mappping = {node: pr for node, pr in zip(graph.nodes(), prs)}\n",
    "    return prs_mappping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This implementations is based on the following formula\n",
    "\n",
    "$$ PR(p_i) = {\\frac{1-d}{N}} + d(\\sum_{p_j\\ links\\ to\\ p_i}{\\frac{PR(p_j)}{L(p_j)}} + \\sum_{p_j\\ has\\ no\\ out-links}{\\frac{PR(p_j)}{N}})$$\n",
    "\n",
    "\n",
    "In each iteration, I first calculate the pageranks that each node can contribute in each edge.  \n",
    "e.g. The pagerank of node 1 is 0.5 and node 1 has 2 outgoing edge. Then, pagerank quota of node 1 would be 0.5/2 = 0.25\n",
    "\n",
    "Next, I calculate the dot product of pagerank quotas and adjcency matrix of the graph.  \n",
    "By doing this, the pagerank quotas are distributed to each ingoing link.  \n",
    "The result would be the $\\sum\\limits_{p_j\\ links\\ to\\ p_i}{\\frac{PR(p_j)}{N}}$ part.\n",
    "\n",
    "After that, the pagerank values of all dangling nodes (i.e. nodes with no outgoing edges) are divided by numbers of nodes and then summed up as `dangle_sum`.\n",
    "This would be the $\\sum\\limits_{p_j\\ has\\ no\\ out-links}{\\frac{PR(p_j)}{L(p_j)}})$ part.\n",
    "\n",
    "Add this two part, multiply damping factor, add ${\\frac{1-d}{N}}$ and then we will get the pagerank result of this iteration.\n",
    "\n",
    "Repeat these steps until the difference between pagerank and pagerank in the previous iteration is smaller than epsilon.\n",
    "\n",
    "### Reference \n",
    "[PageRank Lecture Note](http://www.ccs.northeastern.edu/home/daikeshi/notes/PageRank.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='simrank'></a> SimRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "def simrank(graph, *, C=0.8, epsilon=1e-06):\n",
    "    node_num = graph.number_of_nodes()\n",
    "    adj_matrix = np.array(nx.to_numpy_matrix(graph))\n",
    "    adj_matrix /= np.sum(adj_matrix, axis=0)\n",
    "    adj_matrix = np.nan_to_num(adj_matrix)\n",
    "    \n",
    "    pre_sim = np.zeros(node_num)\n",
    "    sim = np.eye(node_num)\n",
    "    delta = np.sum(np.abs(sim - pre_sim))\n",
    "    while delta > epsilon:\n",
    "        pre_sim = deepcopy(sim)\n",
    "        sim = C * adj_matrix.transpose().dot(pre_sim).dot(adj_matrix)\n",
    "        for i in range(node_num):\n",
    "            sim[i, i] = 1\n",
    "        delta = np.sum(np.abs(sim - pre_sim))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation is based on this formula.\n",
    "\n",
    "$$ S = max\\{C \\cdot (A^T \\cdot S\\cdot A), I\\}$$\n",
    "\n",
    "$A$ is the normalized adjacency matrix whose entry\n",
    "\n",
    "\n",
    "$$ A[a,b]=\\left\\{\n",
    "\\begin{aligned}\n",
    "{\\frac{1}{|I(b)|}},\\ \\text{Edge(a, b) exists}\\\\\n",
    "0,\\ \\text{Otherwise}\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Reference\n",
    "[SimRank - Matrix representation of SimRank](https://en.wikipedia.org/wiki/SimRank#Matrix_representation_of_SimRank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <a name='discussion'></a> Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='result'></a> Result Analysis and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, graph in enumerate(graphs, 1):\n",
    "    print('\\nGraph {}'.format(index))\n",
    "    h,a = hits(graph, np.inf)\n",
    "    print('hub:')\n",
    "    pp.pprint(h)\n",
    "    print('authority:')\n",
    "    pp.pprint(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, graph in enumerate(graphs, 1):\n",
    "    print('\\nGraph {}'.format(index))\n",
    "    pp.pprint(pagerank(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, graph in enumerate(graphs, 1):\n",
    "    print('\\nGraph {}'.format(index))\n",
    "    pp.pprint(simrank(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='performance'></a> Computation Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hits  \n",
    "  \n",
    "Compared with networkx.hits, self-implemented HITS has shorter execution time because it calculates the recursive computation of dot product with numpy.matrix instead of calculating and suming up the dot product value by value like networkx does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for graph in graphs:\n",
    "    hits(graph, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for graph in graphs:\n",
    "    nx.hits(graph, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Page Rank\n",
    "\n",
    "I compare my implementation of pagerank with a well known library - networkx and found that my implementation is faster.  \n",
    "By digging into source code, I found one possible reason is that networkx's implementation is more flexible.  \n",
    "(e.g. It considers the weight of each edge)  \n",
    "Another reason might be that networks's implementation uses `dict` to store values which is much slower than using `numpy` which is used in my implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for graph in graphs:\n",
    "    pagerank(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for graph in graphs:\n",
    "    nx.pagerank(graph, alpha=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SimRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for graph in graphs:\n",
    "    simrank(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hits  \n",
    "  \n",
    "The peak memory of both implementaion is almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "\n",
    "for graph in graphs:\n",
    "    hits(graph, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "\n",
    "for graph in graphs:\n",
    "    nx.hits(graph, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Page Rank\n",
    "\n",
    "The peak memory of both implementaion is close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "\n",
    "for graph in graphs:\n",
    "    pagerank(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "\n",
    "for graph in graphs:\n",
    "    nx.pagerank(graph, alpha=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SimRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%memit\n",
    "\n",
    "for graph in graphs:\n",
    "    simrank(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='increase-hub-authority'></a> Find a way to increase hub, authority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Graph 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1 = deepcopy(graphs[0])\n",
    "h1, a1 = hits(g1)\n",
    "print(\"original hub =\", h1['1'])\n",
    "print(\"original authority =\", a1['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nx.draw(g1,with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To increase hub:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1. Add a link point to node '1' from itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g1_h1= deepcopy(graphs[0])\n",
    "g1_h1.add_edge('1', '1')\n",
    "print(\"original hub =\", h1['1'])\n",
    "print(\"new hub =\",hits(g1_h1)[0]['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mehtod 2. Add a edge from node '1' point to other nodes if the existence of the link will increase the score of hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g1_h2= deepcopy(graphs[0])\n",
    "print(\"original hub =\", h1['1'])\n",
    "h = h1['1']\n",
    "for node in g1_h2.nodes():\n",
    "    if node not in g1_h2.neighbors('1'):\n",
    "        if node is '1':\n",
    "            continue\n",
    "        g1_h2.add_edge('1', node)\n",
    "        new_h = hits(g1_h2)[0]['1']\n",
    "        if new_h <= h:\n",
    "            g1_h2.remove_edge('1',node)\n",
    "        else:\n",
    "            h = new_h\n",
    "            print(\"add edge ( 1 ,\",node,\")\", h)\n",
    "print(\"new hub =\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(g1_h2,with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To increase authority:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1. Add a link point to node '1' to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g1_a1= deepcopy(graphs[0])\n",
    "g1_a1.add_edge('1', '1')\n",
    "print(\"original authority =\", a1['1'])\n",
    "print(\"new authority =\",hits(g1_a1)[1]['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2. Add a edge from other nodes to node '1' if the existence of the link will increase the score of authority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1_a2= deepcopy(graphs[0])\n",
    "print(\"original authority =\", a1['1'])\n",
    "a = a1['1']\n",
    "for node in g1_a2.nodes():\n",
    "    if node not in g1_a2.neighbors('1'):\n",
    "        if node is '1':\n",
    "            continue\n",
    "        g1_a2.add_edge(node, '1')\n",
    "        new_a = hits(g1_a2)[1]['1']\n",
    "        if new_a <= a:\n",
    "            g1_a2.remove_edge(node, '1')\n",
    "        else:\n",
    "            a = new_a\n",
    "            print(\"add edge (\",node,\"1 )\", a)\n",
    "print(\"new authority =\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(g1_a2,with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2 = deepcopy(graphs[1])\n",
    "h2, a2 = hits(g2)\n",
    "print(\"original hub =\", h2['1'])\n",
    "print(\"original authority =\", a2['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(g2,with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To increase hub:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2_h1= deepcopy(graphs[1])\n",
    "g2_h1.add_edge('1', '1')\n",
    "print(\"original hub =\", h2['1'])\n",
    "print(\"new hub =\",hits(g2_h1)[0]['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2_h2= deepcopy(graphs[1])\n",
    "print(\"original hub =\", h2['1'])\n",
    "h = h2['1']\n",
    "for node in g2_h2.nodes():\n",
    "    if node not in g2_h2.neighbors('1'):\n",
    "        if node is '1':\n",
    "            continue\n",
    "        g2_h2.add_edge('1', node)\n",
    "        new_h = hits(g2_h2)[0]['1']\n",
    "        if new_h <= h:\n",
    "            g2_h2.remove_edge('1',node)\n",
    "        else:\n",
    "            h = new_h\n",
    "            print(\"add edge ( 1 ,\",node,\")\", h)\n",
    "print(\"new hub =\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To increase authority:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2_a1= deepcopy(graphs[1])\n",
    "g2_a1.add_edge('1', '1')\n",
    "print(\"original authority =\", a2['1'])\n",
    "print(\"new authority =\",hits(g2_a1)[1]['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2_a2= deepcopy(graphs[1])\n",
    "print(\"original authority =\", a2['1'])\n",
    "a = a2['1']\n",
    "for node in g2_a2.nodes():\n",
    "    if node not in g2_a2.neighbors('1'):\n",
    "        if node is '1':\n",
    "            continue\n",
    "        g2_a2.add_edge(node, '1')\n",
    "        new_a = hits(g2_a2)[1]['1']\n",
    "        if new_a <= a:\n",
    "            g2_a2.remove_edge(node, '1')\n",
    "        else:\n",
    "            a = new_a\n",
    "            print(\"add edge (\",node,\"1 )\", a)\n",
    "print(\"new authority =\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g3 = deepcopy(graphs[2])\n",
    "h3, a3 = hits(g3)\n",
    "print(\"original hub =\", h2['3'])\n",
    "print(\"original authority =\", a2['3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(g3,with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To increase hub:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g3_h1= deepcopy(graphs[2])\n",
    "g3_h1.add_edge('1', '1')\n",
    "print(\"original hub =\", h3['1'])\n",
    "print(\"new hub =\",hits(g3_h1)[0]['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g3_h2= deepcopy(graphs[2])\n",
    "print(\"original hub =\", h3['1'])\n",
    "h = h3['1']\n",
    "for node in g3_h2.nodes():\n",
    "    if node not in g3_h2.neighbors('1'):\n",
    "        if node is '1':\n",
    "            continue\n",
    "        g3_h2.add_edge('1', node)\n",
    "        new_h = hits(g3_h2)[0]['1']\n",
    "        if new_h <= h:\n",
    "            g3_h2.remove_edge('1',node)\n",
    "        else:\n",
    "            h = new_h\n",
    "            print(\"add edge ( 1 ,\",node,\")\", h)\n",
    "print(\"new hub =\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To increase authority:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g3_a1= deepcopy(graphs[2])\n",
    "g3_a1.add_edge('1', '1')\n",
    "print(\"original authority =\", a3['1'])\n",
    "print(\"new authority =\",hits(g3_a1)[1]['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g3_a2= deepcopy(graphs[2])\n",
    "print(\"original authority =\", a3['1'])\n",
    "a = a3['1']\n",
    "for node in g3_a2.nodes():\n",
    "    if node not in g3_a2.neighbors('1'):\n",
    "        if node is '1':\n",
    "            continue\n",
    "        g3_a2.add_edge(node, '1')\n",
    "        new_a = hits(g3_a2)[1]['1']\n",
    "        if new_a <= a:\n",
    "            g3_a2.remove_edge(node, '1')\n",
    "        else:\n",
    "            a = new_a\n",
    "            print(\"add edge (\",node,\"1 )\", a)\n",
    "print(\"new authority =\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Conclusion\n",
    "- Hub:\n",
    "    - The main idea of increasing score of hub is based on \"A good hub is a site that links to many authoritative sites\", so I increase the number of outgoing edges of node 1 with the constraints of higher hubness. \n",
    "    - Method 1: It cuts corners to add a link from 1 to 1 which is significantly useful only in graph 1.\n",
    "    - Method 2: This method is more effective in all of three graphs than method 1.\n",
    "- Authority:\n",
    "    - Following the concept that \"A site is very authoritative if it receives many citations,\" I use the following method to increace the number of nodes which point to node 1.\n",
    "    - Method 1: This method performs more well only in graph 2 which is a circular graph.\n",
    "    - Method 2: In average, it elevates all the socre of authority in all graph above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='increase-pagerank'></a> Find a way to increase pagerank\n",
    "\n",
    "The goal of this section is to increase pagerank of node 1.  \n",
    "Since modifying others' links is not that practical in real world, the operation here would only consider manipulating edge of node 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1 = deepcopy(graphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1_original_pagerank = pagerank(g1)\n",
    "g1_original_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add an edge from node 1 to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dest in ['3', '4', '5', '6']:\n",
    "    g1.add_edge('1', dest)\n",
    "    print(\"Page Rank after adding edge 1 -> {dest}:\".format(dest=dest), pagerank(g1)['1'])\n",
    "    g1.remove_edge('1', dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result shows, by adding edge (1, 3) and (1, 6) can increase pagerank of node 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g2 = deepcopy(graphs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2_origin_pagerank = pagerank(g2)\n",
    "g2_origin_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add an edge from node 1 to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dest in ['3', '4', '5', '6']:\n",
    "    g2.add_edge('1', dest)\n",
    "    print(\"Page Rank after adding edge 1 -> {dest}:\".format(dest=dest), pagerank(g2)['1'])\n",
    "    g2.remove_edge('1', dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result shows, by adding an edge from node 1 to any other node increases pagerank of node 1.  \n",
    "The impact of the added edge grows stronger when the destination node of it can link to node 1 in a shorter path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g3 = deepcopy(graphs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g3_origin_pagerank = pagerank(g3)\n",
    "g3_origin_pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add an edge from node 1 to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dest in ['3', '4']:\n",
    "    g3.add_edge('1', dest)\n",
    "    print(\"Page Rank after adding edge 1 -> {dest}:\".format(dest=dest), pagerank(g3)['1'])\n",
    "    g3.remove_edge('1', dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding node from node 1 to any other node cannot increase pagerank of node 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove an edge from node 1 while not making it become isolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g3.remove_edge('1', '2')\n",
    "print(\"Page Rank after removing edge 1 -> 2: \", pagerank(g3)['1'])\n",
    "g3.add_edge('1', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result shows, by removing edge (1, 2) can increase pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings\n",
    "- If one page is linked by others, then linking to these pages would increases its pagerank.  \n",
    "  If not directly linked, linking to the pages whose path to this page are shorter would have a stronger effect.  \n",
    "  This happens due to the fact that one's pankrank is decided by others.  \n",
    "  If this page contributes more to pages that can contribute more to itself (i.e. pages whose path is shorter to this page), then its rank would be higher.\n",
    "- If one page is not linked by others, but links to others, then by breaking these links it would get a higher pagerank.  \n",
    "  Because it can share distributed ranking value of dangling nodes instead of contributing all these values to otheres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='important'></a> Can link analysis algorithms really find the “important” pages from Web?\n",
    "\n",
    "According section [Find a way to increase hub, authority](#increase-hub-authority) and section [Find a way to increase pagerank](#increase-pagerank), it's possible to manipulate the important of these values.  \n",
    "Thus, we can hardly say these algorithms can find the really important pages from Web.  \n",
    "  \n",
    "Besides, these algorithms consider only relationships between pages instead of their content which might be one of the crucial indicators of  deciding which pages are important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='c-in-simrank'></a> What is the effect of “C” parameter in SimRank?\n",
    "\n",
    "Consider the following scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gt = nx.DiGraph()\n",
    "Gt.add_edge(1, 2)\n",
    "Gt.add_edge(3, 2)\n",
    "nx.draw(Gt, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would say that S(1, 3) might be high since they link to the same node. This is the basic idea of SimRank.  \n",
    "However, we probably won't conclude that $S(1,3) = S(2,2) = 1$  \n",
    "Node 1 and 3 might be similiar but the similiarity should not be the same as identical nodes'.  \n",
    "Thus, the decay factor C whose value is between 0 and 1 can be used to handle this problem\n",
    "\n",
    "### Reference\n",
    "[SimRank: A Measure of Structural-Context Similiarity](http://dc-pubs.dbs.uni-leipzig.de/files/Jeh2002SimRankameasureof.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='practical-issue'></a> What are practical issues when implement these algorithms in a real Web?   \n",
    "  \n",
    "In the real world, I think that efficiency is sometimes more important than accuracy.  \n",
    "That's to say, while we consider to raise the values of hubness and authority in HITS as high as possible, and so does pagerank and simrank in experiment, what does matter may be the fact that users cannot wait more than ten seconds after pressing the \"return\" and expecting for the result on the search engine.  \n",
    "Therefore, the practical issue is how to get the query results with not low relevance and highest efficency.\n",
    "There will be a trade-off among short response time and authoritative websie when apply the algorithm in real Web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name='conclusion'></a> Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After implementing these algorithms about link analysis, we find out that it is not eazy to attract what's really important and relevant among so many websites on the Internet.  \n",
    "The algorithms we implement in project 3 have different characteristics and suitable situations, so we should apply them into fitting conditions for highest proformance. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
